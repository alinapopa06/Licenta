Consider the model function y = α + β * x, which describes a line with slope β and y-intercept α. In general such a relationship may not hold exactly for the largely unobserved population of values of the independent and dependent variables; we call the unobserved deviations from the above equation the errors. Suppose we observe n data pairs and call them {(xi, yi), i = 1, ..., n}. We can describe the underlying relationship between yi and xi involving this error term εi by yi = α + β * xi + εi. This relationship between the true (but unobserved) underlying parameters α and β and the data points is called a linear regression model.